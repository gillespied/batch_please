{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"batch_please","text":"<p>A flexible and efficient Python library for processing large datasets in batches, with support for both synchronous and asynchronous operations.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Process large datasets in customizable batch sizes</li> <li>Support for both synchronous and asynchronous processing</li> <li>Checkpoint functionality to resume processing from where it left off</li> <li>Optional progress bar using tqdm</li> <li>Configurable concurrency limit for asynchronous processing</li> <li>Logging support</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install batch-processor  \n</code></pre>"},{"location":"#quick-start","title":"Quick Start","text":""},{"location":"#synchronous-processing","title":"Synchronous Processing","text":"<pre><code>from batch_processor import BatchProcessor\n\ndef process_func(item):\n    return f\"Processed: {item}\"\n\nprocessor = BatchProcessor(\n    process_func=process_func,\n    batch_size=100,\n    use_tqdm=True\n)\n\ninput_data = range(1000)\nprocessed_items, results = processor.process_items_in_batches(input_data)\n</code></pre>"},{"location":"#asynchronous-processing","title":"Asynchronous Processing","text":"<pre><code>import asyncio\nfrom batch_processor import AsyncBatchProcessor\n\nasync def async_process_func(item):\n    await asyncio.sleep(0.1)\n    return f\"Processed: {item}\"\n\nasync def main():\n    processor = AsyncBatchProcessor(\n        process_func=async_process_func,\n        batch_size=100,\n        max_concurrent=10,\n        use_tqdm=True\n    )\n\n    input_data = range(1000)\n    processed_items, results = await processor.process_items_in_batches(input_data)\n\nasyncio.run(main())\n</code></pre>"},{"location":"#advanced-usage","title":"Advanced Usage","text":""},{"location":"#checkpoint-recovery","title":"Checkpoint Recovery","text":"<pre><code>processor = BatchProcessor(\n    process_func=process_func,\n    batch_size=100,\n    pickle_file=\"checkpoint.pkl\",\n    recover_from_checkpoint=True\n)\n</code></pre>"},{"location":"#logging","title":"Logging","text":"<pre><code>processor = BatchProcessor(\n    process_func=process_func,\n    batch_size=100,\n    logfile=\"processing.log\"\n)\n</code></pre>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#batchprocessor","title":"BatchProcessor","text":""},{"location":"api/#batch_processors.batchers.BatchProcessor","title":"<code>batch_processors.batchers.BatchProcessor</code>","text":"<p>               Bases: <code>Generic[T, R]</code></p> <p>A class for processing items in batches.</p> <p>This class takes an iterable of items, processes them in batches using a provided function, and optionally saves progress to allow for checkpoint recovery.</p> <p>Attributes:</p> Name Type Description <code>process_func</code> <code>Callable[[T], R]</code> <p>The function used to process each item.</p> <code>batch_size</code> <code>int</code> <p>The number of items to process in each batch.</p> <code>pickle_file</code> <code>Optional[str]</code> <p>The file to use for saving/loading progress.</p> <code>processed_items</code> <code>List[T]</code> <p>A list of items that have been processed.</p> <code>results</code> <code>List[R]</code> <p>A list of results from processing the items.</p> <code>recover_from_checkpoint</code> <code>bool</code> <p>Whether to attempt to recover from a checkpoint.</p> <code>use_tqdm</code> <code>bool</code> <p>Whether to use tqdm progress bars.</p> Source code in <code>src/batch_processors/batchers.py</code> <pre><code>class BatchProcessor(Generic[T, R]):\n    \"\"\"\n    A class for processing items in batches.\n\n    This class takes an iterable of items, processes them in batches using a provided\n    function, and optionally saves progress to allow for checkpoint recovery.\n\n    Attributes:\n        process_func (Callable[[T], R]): The function used to process each item.\n        batch_size (int): The number of items to process in each batch.\n        pickle_file (Optional[str]): The file to use for saving/loading progress.\n        processed_items (List[T]): A list of items that have been processed.\n        results (List[R]): A list of results from processing the items.\n        recover_from_checkpoint (bool): Whether to attempt to recover from a checkpoint.\n        use_tqdm (bool): Whether to use tqdm progress bars.\n    \"\"\"\n\n    def __init__(\n        self,\n        process_func: Callable[[T], R],\n        batch_size: int = 100,\n        pickle_file: Optional[str] = None,\n        logfile: Optional[str] = None,\n        recover_from_checkpoint: bool = False,\n        use_tqdm: bool = False,\n    ):\n        \"\"\"\n        Initialize the BatchProcessor.\n\n        Args:\n            process_func (Callable[[T], R]): The function to process each item.\n            batch_size (int, optional): The number of items to process in each batch. Defaults to 100.\n            pickle_file (Optional[str], optional): The file to use for saving/loading progress. Defaults to None.\n            logfile (Optional[str], optional): The file to use for logging. Defaults to None.\n            recover_from_checkpoint (bool, optional): Whether to attempt to recover from a checkpoint. Defaults to False.\n            use_tqdm (bool, optional): Whether to use tqdm progress bars. Defaults to False.\n        \"\"\"\n        self.process_func = process_func\n        self.batch_size = batch_size\n        self.pickle_file = pickle_file\n        self.processed_items: List[T] = []\n        self.results: List[R] = []\n        self.recover_from_checkpoint = recover_from_checkpoint\n        self.use_tqdm = use_tqdm\n\n        # Set up logging\n        self.logger = logging.getLogger(__name__)\n        self.logger.setLevel(logging.INFO)\n        self.logger.handlers = []  # Clear any existing handlers\n        formatter = logging.Formatter(\"%(asctime)s - %(message)s\")\n\n        # File handler (if logfile is provided)\n        if logfile:\n            file_handler = logging.FileHandler(logfile)\n            file_handler.setFormatter(formatter)\n            self.logger.addHandler(file_handler)\n\n        # Recover from checkpoint if enabled\n        if self.recover_from_checkpoint:\n            self.load_progress()\n\n    def process_item(self, job_number: int, item: T) -&gt; R:\n        \"\"\"\n        Process a single item.\n\n        Args:\n            job_number (int): The number of the job being processed.\n            item (T): The item to process.\n\n        Returns:\n            R: The result of processing the item.\n        \"\"\"\n        result = self.process_func(item)\n        self.logger.info(f\"Processed job {job_number}: {item}\")\n        return result\n\n    def process_batch(self, batch: List[T], batch_number: int, total_jobs: int):\n        \"\"\"\n        Process a batch of items.\n\n        Args:\n            batch (List[T]): The batch of items to process.\n            batch_number (int): The number of the current batch.\n            total_jobs (int): The total number of jobs to process.\n        \"\"\"\n        if self.use_tqdm:\n            batch_results = [\n                self.process_item(i, item)\n                for i, item in enumerate(tqdm(batch, desc=f\"Batch {batch_number}\"))\n            ]\n        else:\n            batch_results = [self.process_item(i, item) for i, item in enumerate(batch)]\n\n        self.processed_items.extend(batch)\n        self.results.extend(batch_results)\n\n        if self.pickle_file:\n            self.save_progress()\n\n        completion_message = f\"Batch {batch_number} completed. Total processed: {len(self.processed_items)}/{total_jobs}\"\n        print(completion_message)\n        self.logger.info(completion_message)\n\n    def load_progress(self):\n        \"\"\"\n        Load progress from a checkpoint file if it exists.\n        \"\"\"\n        if self.pickle_file and os.path.exists(self.pickle_file):\n            with open(self.pickle_file, \"rb\") as f:\n                data = pickle.load(f)\n                self.processed_items = data[\"processed_items\"]\n                self.results = data[\"results\"]\n            self.logger.info(\n                f\"Recovered {len(self.processed_items)} items from checkpoint\"\n            )\n        else:\n            self.logger.info(\n                \"No checkpoint file found or checkpoint recovery not enabled\"\n            )\n\n    def save_progress(self):\n        \"\"\"\n        Save current progress to a checkpoint file.\n        \"\"\"\n        with open(self.pickle_file, \"wb\") as f:\n            pickle.dump(\n                {\"processed_items\": self.processed_items, \"results\": self.results},\n                f,\n            )\n\n    def process_items_in_batches(\n        self, input_items: Iterable[T]\n    ) -&gt; Tuple[List[T], List[R]]:\n        \"\"\"\n        Process all input items in batches.\n\n        Args:\n            input_items (Iterable[T]): The items to process.\n\n        Returns:\n            Tuple[List[T], List[R]]: A tuple containing the list of processed items and their results.\n        \"\"\"\n        input_items = list(input_items)  # Convert iterable to list\n        total_jobs = len(input_items)\n        start_index = len(self.processed_items) if self.recover_from_checkpoint else 0\n\n        for i in range(start_index, total_jobs, self.batch_size):\n            batch = input_items[i : i + self.batch_size]\n            self.process_batch(batch, i // self.batch_size + 1, total_jobs)\n\n        return self.processed_items, self.results\n</code></pre>"},{"location":"api/#batch_processors.batchers.BatchProcessor.__init__","title":"<code>__init__(process_func, batch_size=100, pickle_file=None, logfile=None, recover_from_checkpoint=False, use_tqdm=False)</code>","text":"<p>Initialize the BatchProcessor.</p> <p>Parameters:</p> Name Type Description Default <code>process_func</code> <code>Callable[[T], R]</code> <p>The function to process each item.</p> required <code>batch_size</code> <code>int</code> <p>The number of items to process in each batch. Defaults to 100.</p> <code>100</code> <code>pickle_file</code> <code>Optional[str]</code> <p>The file to use for saving/loading progress. Defaults to None.</p> <code>None</code> <code>logfile</code> <code>Optional[str]</code> <p>The file to use for logging. Defaults to None.</p> <code>None</code> <code>recover_from_checkpoint</code> <code>bool</code> <p>Whether to attempt to recover from a checkpoint. Defaults to False.</p> <code>False</code> <code>use_tqdm</code> <code>bool</code> <p>Whether to use tqdm progress bars. Defaults to False.</p> <code>False</code> Source code in <code>src/batch_processors/batchers.py</code> <pre><code>def __init__(\n    self,\n    process_func: Callable[[T], R],\n    batch_size: int = 100,\n    pickle_file: Optional[str] = None,\n    logfile: Optional[str] = None,\n    recover_from_checkpoint: bool = False,\n    use_tqdm: bool = False,\n):\n    \"\"\"\n    Initialize the BatchProcessor.\n\n    Args:\n        process_func (Callable[[T], R]): The function to process each item.\n        batch_size (int, optional): The number of items to process in each batch. Defaults to 100.\n        pickle_file (Optional[str], optional): The file to use for saving/loading progress. Defaults to None.\n        logfile (Optional[str], optional): The file to use for logging. Defaults to None.\n        recover_from_checkpoint (bool, optional): Whether to attempt to recover from a checkpoint. Defaults to False.\n        use_tqdm (bool, optional): Whether to use tqdm progress bars. Defaults to False.\n    \"\"\"\n    self.process_func = process_func\n    self.batch_size = batch_size\n    self.pickle_file = pickle_file\n    self.processed_items: List[T] = []\n    self.results: List[R] = []\n    self.recover_from_checkpoint = recover_from_checkpoint\n    self.use_tqdm = use_tqdm\n\n    # Set up logging\n    self.logger = logging.getLogger(__name__)\n    self.logger.setLevel(logging.INFO)\n    self.logger.handlers = []  # Clear any existing handlers\n    formatter = logging.Formatter(\"%(asctime)s - %(message)s\")\n\n    # File handler (if logfile is provided)\n    if logfile:\n        file_handler = logging.FileHandler(logfile)\n        file_handler.setFormatter(formatter)\n        self.logger.addHandler(file_handler)\n\n    # Recover from checkpoint if enabled\n    if self.recover_from_checkpoint:\n        self.load_progress()\n</code></pre>"},{"location":"api/#batch_processors.batchers.BatchProcessor.load_progress","title":"<code>load_progress()</code>","text":"<p>Load progress from a checkpoint file if it exists.</p> Source code in <code>src/batch_processors/batchers.py</code> <pre><code>def load_progress(self):\n    \"\"\"\n    Load progress from a checkpoint file if it exists.\n    \"\"\"\n    if self.pickle_file and os.path.exists(self.pickle_file):\n        with open(self.pickle_file, \"rb\") as f:\n            data = pickle.load(f)\n            self.processed_items = data[\"processed_items\"]\n            self.results = data[\"results\"]\n        self.logger.info(\n            f\"Recovered {len(self.processed_items)} items from checkpoint\"\n        )\n    else:\n        self.logger.info(\n            \"No checkpoint file found or checkpoint recovery not enabled\"\n        )\n</code></pre>"},{"location":"api/#batch_processors.batchers.BatchProcessor.process_batch","title":"<code>process_batch(batch, batch_number, total_jobs)</code>","text":"<p>Process a batch of items.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>List[T]</code> <p>The batch of items to process.</p> required <code>batch_number</code> <code>int</code> <p>The number of the current batch.</p> required <code>total_jobs</code> <code>int</code> <p>The total number of jobs to process.</p> required Source code in <code>src/batch_processors/batchers.py</code> <pre><code>def process_batch(self, batch: List[T], batch_number: int, total_jobs: int):\n    \"\"\"\n    Process a batch of items.\n\n    Args:\n        batch (List[T]): The batch of items to process.\n        batch_number (int): The number of the current batch.\n        total_jobs (int): The total number of jobs to process.\n    \"\"\"\n    if self.use_tqdm:\n        batch_results = [\n            self.process_item(i, item)\n            for i, item in enumerate(tqdm(batch, desc=f\"Batch {batch_number}\"))\n        ]\n    else:\n        batch_results = [self.process_item(i, item) for i, item in enumerate(batch)]\n\n    self.processed_items.extend(batch)\n    self.results.extend(batch_results)\n\n    if self.pickle_file:\n        self.save_progress()\n\n    completion_message = f\"Batch {batch_number} completed. Total processed: {len(self.processed_items)}/{total_jobs}\"\n    print(completion_message)\n    self.logger.info(completion_message)\n</code></pre>"},{"location":"api/#batch_processors.batchers.BatchProcessor.process_item","title":"<code>process_item(job_number, item)</code>","text":"<p>Process a single item.</p> <p>Parameters:</p> Name Type Description Default <code>job_number</code> <code>int</code> <p>The number of the job being processed.</p> required <code>item</code> <code>T</code> <p>The item to process.</p> required <p>Returns:</p> Name Type Description <code>R</code> <code>R</code> <p>The result of processing the item.</p> Source code in <code>src/batch_processors/batchers.py</code> <pre><code>def process_item(self, job_number: int, item: T) -&gt; R:\n    \"\"\"\n    Process a single item.\n\n    Args:\n        job_number (int): The number of the job being processed.\n        item (T): The item to process.\n\n    Returns:\n        R: The result of processing the item.\n    \"\"\"\n    result = self.process_func(item)\n    self.logger.info(f\"Processed job {job_number}: {item}\")\n    return result\n</code></pre>"},{"location":"api/#batch_processors.batchers.BatchProcessor.process_items_in_batches","title":"<code>process_items_in_batches(input_items)</code>","text":"<p>Process all input items in batches.</p> <p>Parameters:</p> Name Type Description Default <code>input_items</code> <code>Iterable[T]</code> <p>The items to process.</p> required <p>Returns:</p> Type Description <code>Tuple[List[T], List[R]]</code> <p>Tuple[List[T], List[R]]: A tuple containing the list of processed items and their results.</p> Source code in <code>src/batch_processors/batchers.py</code> <pre><code>def process_items_in_batches(\n    self, input_items: Iterable[T]\n) -&gt; Tuple[List[T], List[R]]:\n    \"\"\"\n    Process all input items in batches.\n\n    Args:\n        input_items (Iterable[T]): The items to process.\n\n    Returns:\n        Tuple[List[T], List[R]]: A tuple containing the list of processed items and their results.\n    \"\"\"\n    input_items = list(input_items)  # Convert iterable to list\n    total_jobs = len(input_items)\n    start_index = len(self.processed_items) if self.recover_from_checkpoint else 0\n\n    for i in range(start_index, total_jobs, self.batch_size):\n        batch = input_items[i : i + self.batch_size]\n        self.process_batch(batch, i // self.batch_size + 1, total_jobs)\n\n    return self.processed_items, self.results\n</code></pre>"},{"location":"api/#batch_processors.batchers.BatchProcessor.save_progress","title":"<code>save_progress()</code>","text":"<p>Save current progress to a checkpoint file.</p> Source code in <code>src/batch_processors/batchers.py</code> <pre><code>def save_progress(self):\n    \"\"\"\n    Save current progress to a checkpoint file.\n    \"\"\"\n    with open(self.pickle_file, \"wb\") as f:\n        pickle.dump(\n            {\"processed_items\": self.processed_items, \"results\": self.results},\n            f,\n        )\n</code></pre>"},{"location":"api/#asyncbatchprocessor","title":"AsyncBatchProcessor","text":"<p>```</p>"},{"location":"api/#batch_processors.batchers.AsyncBatchProcessor","title":"<code>batch_processors.batchers.AsyncBatchProcessor</code>","text":"<p>               Bases: <code>BatchProcessor[T, R]</code></p> <p>An asynchronous version of the BatchProcessor.</p> <p>This class processes items in batches asynchronously, with optional concurrency limits.</p> Source code in <code>src/batch_processors/batchers.py</code> <pre><code>class AsyncBatchProcessor(BatchProcessor[T, R]):\n    \"\"\"\n    An asynchronous version of the BatchProcessor.\n\n    This class processes items in batches asynchronously, with optional concurrency limits.\n    \"\"\"\n\n    def __init__(\n        self,\n        process_func: Callable[[T], R],\n        batch_size: int = 100,\n        pickle_file: Optional[str] = None,\n        logfile: Optional[str] = None,\n        recover_from_checkpoint: bool = False,\n        max_concurrent: Optional[int] = None,\n        use_tqdm: bool = False,\n    ):\n        \"\"\"\n        Initialize the AsyncBatchProcessor.\n\n        Args:\n            process_func (Callable[[T], R]): The function to process each item.\n            batch_size (int, optional): The number of items to process in each batch. Defaults to 100.\n            pickle_file (Optional[str], optional): The file to use for saving/loading progress. Defaults to None.\n            logfile (Optional[str], optional): The file to use for logging. Defaults to None.\n            recover_from_checkpoint (bool, optional): Whether to attempt to recover from a checkpoint. Defaults to False.\n            max_concurrent (Optional[int], optional): The maximum number of concurrent operations. Defaults to None.\n            use_tqdm (bool, optional): Whether to use tqdm progress bars. Defaults to False.\n        \"\"\"\n        super().__init__(\n            process_func,\n            batch_size,\n            pickle_file,\n            logfile,\n            recover_from_checkpoint,\n            use_tqdm,\n        )\n        self.semaphore = (\n            asyncio.Semaphore(max_concurrent) if max_concurrent is not None else None\n        )\n\n    async def process_item(self, job_number: int, item: T) -&gt; R:\n        \"\"\"\n        Process a single item asynchronously.\n\n        Args:\n            job_number (int): The number of the job being processed.\n            item (T): The item to process.\n\n        Returns:\n            R: The result of processing the item.\n        \"\"\"\n\n        async def _process():\n            result = await self.process_func(item)\n            self.logger.info(f\"Processed job {job_number}: {item}\")\n            return result\n\n        if self.semaphore:\n            async with self.semaphore:\n                return await _process()\n        else:\n            return await _process()\n\n    async def process_batch(self, batch: List[T], batch_number: int, total_jobs: int):\n        \"\"\"\n        Process a batch of items asynchronously.\n\n        Args:\n            batch (List[T]): The batch of items to process.\n            batch_number (int): The number of the current batch.\n            total_jobs (int): The total number of jobs to process.\n        \"\"\"\n        if self.use_tqdm:\n            pbar = tqdm(total=len(batch), desc=f\"Batch {batch_number}\")\n\n        tasks = [\n            self.process_item(i + (batch_number - 1) * self.batch_size, item)\n            for i, item in enumerate(batch)\n        ]\n\n        batch_results = []\n        for task in asyncio.as_completed(tasks):\n            result = await task\n            batch_results.append(result)\n            if self.use_tqdm:\n                pbar.update(1)\n\n        if self.use_tqdm:\n            pbar.close()\n\n        self.processed_items.extend(batch)\n        self.results.extend(batch_results)\n\n        if self.pickle_file:\n            self.save_progress()\n\n        self.logger.info(\n            f\"Batch {batch_number} completed. Total processed: {len(self.processed_items)}/{total_jobs}\"\n        )\n\n    async def process_items_in_batches(\n        self, input_items: Iterable[T]\n    ) -&gt; Tuple[List[T], List[R]]:\n        \"\"\"\n        Process all input items in batches asynchronously.\n\n        Args:\n            input_items (Iterable[T]): The items to process.\n\n        Returns:\n            Tuple[List[T], List[R]]: A tuple containing the list of processed items and their results.\n        \"\"\"\n        input_items = list(input_items)  # Convert iterable to list\n        total_jobs = len(input_items)\n        start_index = len(self.processed_items) if self.recover_from_checkpoint else 0\n\n        for i in range(start_index, total_jobs, self.batch_size):\n            batch = input_items[i : i + self.batch_size]\n            await self.process_batch(batch, i // self.batch_size + 1, total_jobs)\n\n        return self.processed_items, self.results\n</code></pre>"},{"location":"api/#batch_processors.batchers.AsyncBatchProcessor.__init__","title":"<code>__init__(process_func, batch_size=100, pickle_file=None, logfile=None, recover_from_checkpoint=False, max_concurrent=None, use_tqdm=False)</code>","text":"<p>Initialize the AsyncBatchProcessor.</p> <p>Parameters:</p> Name Type Description Default <code>process_func</code> <code>Callable[[T], R]</code> <p>The function to process each item.</p> required <code>batch_size</code> <code>int</code> <p>The number of items to process in each batch. Defaults to 100.</p> <code>100</code> <code>pickle_file</code> <code>Optional[str]</code> <p>The file to use for saving/loading progress. Defaults to None.</p> <code>None</code> <code>logfile</code> <code>Optional[str]</code> <p>The file to use for logging. Defaults to None.</p> <code>None</code> <code>recover_from_checkpoint</code> <code>bool</code> <p>Whether to attempt to recover from a checkpoint. Defaults to False.</p> <code>False</code> <code>max_concurrent</code> <code>Optional[int]</code> <p>The maximum number of concurrent operations. Defaults to None.</p> <code>None</code> <code>use_tqdm</code> <code>bool</code> <p>Whether to use tqdm progress bars. Defaults to False.</p> <code>False</code> Source code in <code>src/batch_processors/batchers.py</code> <pre><code>def __init__(\n    self,\n    process_func: Callable[[T], R],\n    batch_size: int = 100,\n    pickle_file: Optional[str] = None,\n    logfile: Optional[str] = None,\n    recover_from_checkpoint: bool = False,\n    max_concurrent: Optional[int] = None,\n    use_tqdm: bool = False,\n):\n    \"\"\"\n    Initialize the AsyncBatchProcessor.\n\n    Args:\n        process_func (Callable[[T], R]): The function to process each item.\n        batch_size (int, optional): The number of items to process in each batch. Defaults to 100.\n        pickle_file (Optional[str], optional): The file to use for saving/loading progress. Defaults to None.\n        logfile (Optional[str], optional): The file to use for logging. Defaults to None.\n        recover_from_checkpoint (bool, optional): Whether to attempt to recover from a checkpoint. Defaults to False.\n        max_concurrent (Optional[int], optional): The maximum number of concurrent operations. Defaults to None.\n        use_tqdm (bool, optional): Whether to use tqdm progress bars. Defaults to False.\n    \"\"\"\n    super().__init__(\n        process_func,\n        batch_size,\n        pickle_file,\n        logfile,\n        recover_from_checkpoint,\n        use_tqdm,\n    )\n    self.semaphore = (\n        asyncio.Semaphore(max_concurrent) if max_concurrent is not None else None\n    )\n</code></pre>"},{"location":"api/#batch_processors.batchers.AsyncBatchProcessor.process_batch","title":"<code>process_batch(batch, batch_number, total_jobs)</code>  <code>async</code>","text":"<p>Process a batch of items asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>batch</code> <code>List[T]</code> <p>The batch of items to process.</p> required <code>batch_number</code> <code>int</code> <p>The number of the current batch.</p> required <code>total_jobs</code> <code>int</code> <p>The total number of jobs to process.</p> required Source code in <code>src/batch_processors/batchers.py</code> <pre><code>async def process_batch(self, batch: List[T], batch_number: int, total_jobs: int):\n    \"\"\"\n    Process a batch of items asynchronously.\n\n    Args:\n        batch (List[T]): The batch of items to process.\n        batch_number (int): The number of the current batch.\n        total_jobs (int): The total number of jobs to process.\n    \"\"\"\n    if self.use_tqdm:\n        pbar = tqdm(total=len(batch), desc=f\"Batch {batch_number}\")\n\n    tasks = [\n        self.process_item(i + (batch_number - 1) * self.batch_size, item)\n        for i, item in enumerate(batch)\n    ]\n\n    batch_results = []\n    for task in asyncio.as_completed(tasks):\n        result = await task\n        batch_results.append(result)\n        if self.use_tqdm:\n            pbar.update(1)\n\n    if self.use_tqdm:\n        pbar.close()\n\n    self.processed_items.extend(batch)\n    self.results.extend(batch_results)\n\n    if self.pickle_file:\n        self.save_progress()\n\n    self.logger.info(\n        f\"Batch {batch_number} completed. Total processed: {len(self.processed_items)}/{total_jobs}\"\n    )\n</code></pre>"},{"location":"api/#batch_processors.batchers.AsyncBatchProcessor.process_item","title":"<code>process_item(job_number, item)</code>  <code>async</code>","text":"<p>Process a single item asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>job_number</code> <code>int</code> <p>The number of the job being processed.</p> required <code>item</code> <code>T</code> <p>The item to process.</p> required <p>Returns:</p> Name Type Description <code>R</code> <code>R</code> <p>The result of processing the item.</p> Source code in <code>src/batch_processors/batchers.py</code> <pre><code>async def process_item(self, job_number: int, item: T) -&gt; R:\n    \"\"\"\n    Process a single item asynchronously.\n\n    Args:\n        job_number (int): The number of the job being processed.\n        item (T): The item to process.\n\n    Returns:\n        R: The result of processing the item.\n    \"\"\"\n\n    async def _process():\n        result = await self.process_func(item)\n        self.logger.info(f\"Processed job {job_number}: {item}\")\n        return result\n\n    if self.semaphore:\n        async with self.semaphore:\n            return await _process()\n    else:\n        return await _process()\n</code></pre>"},{"location":"api/#batch_processors.batchers.AsyncBatchProcessor.process_items_in_batches","title":"<code>process_items_in_batches(input_items)</code>  <code>async</code>","text":"<p>Process all input items in batches asynchronously.</p> <p>Parameters:</p> Name Type Description Default <code>input_items</code> <code>Iterable[T]</code> <p>The items to process.</p> required <p>Returns:</p> Type Description <code>Tuple[List[T], List[R]]</code> <p>Tuple[List[T], List[R]]: A tuple containing the list of processed items and their results.</p> Source code in <code>src/batch_processors/batchers.py</code> <pre><code>async def process_items_in_batches(\n    self, input_items: Iterable[T]\n) -&gt; Tuple[List[T], List[R]]:\n    \"\"\"\n    Process all input items in batches asynchronously.\n\n    Args:\n        input_items (Iterable[T]): The items to process.\n\n    Returns:\n        Tuple[List[T], List[R]]: A tuple containing the list of processed items and their results.\n    \"\"\"\n    input_items = list(input_items)  # Convert iterable to list\n    total_jobs = len(input_items)\n    start_index = len(self.processed_items) if self.recover_from_checkpoint else 0\n\n    for i in range(start_index, total_jobs, self.batch_size):\n        batch = input_items[i : i + self.batch_size]\n        await self.process_batch(batch, i // self.batch_size + 1, total_jobs)\n\n    return self.processed_items, self.results\n</code></pre>"}]}